# ğŸš€ AI Chat System - Setup Guide

## Overview

Há»‡ thá»‘ng chat AI hybrid vá»›i 3 má»©c Ä‘á»™ xá»­ lÃ½:

- **Simple** (Danh sÃ¡ch, tÃ¬m kiáº¿m): Neo4j + API
- **Medium** (So sÃ¡nh, phÃ¢n tÃ­ch): ChromaDB + Neo4j
- **Complex** (Giá»›i thiá»‡u, lÃ½ luáº­n): Gemini API

---

## ğŸ“‹ Prerequisites

### 1. Backend Dependencies (âœ… ÄÃ£ cÃ i)

```bash
npm install --save @google/generative-ai axios chromadb dotenv
```

### 2. Environment Variables (âœ… ÄÃ£ cáº­p nháº­t .env)

```dotenv
# AI & Chat Configuration
GEMINI_API_KEY=AIzaSyCgfQsbwmulX0qdWQOIx_-LODiVWhryBxc
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=mistral
CHROMADB_PATH=./data/chromadb
```

---

## ğŸ³ Step 1: Setup Ollama (Local LLM Model)

### Option A: Docker (Recommended)

1. **CÃ i Docker** (náº¿u chÆ°a cÃ³):
   - Windows: https://www.docker.com/products/docker-desktop
   - Táº£i vÃ  cÃ i Ä‘áº·t

2. **Run Ollama Container**:

   ```bash
   # Pull Ollama image
   docker pull ollama/ollama

   # Run container (port 11434)
   docker run -d \
     --name ollama \
     -p 11434:11434 \
     -v ollama:/root/.ollama \
     ollama/ollama
   ```

3. **Download Model** (chá»n 1 trong cÃ¡c sau):

   ```bash
   # Mistral (7B, ~5GB, nhanh, cháº¥t lÆ°á»£ng tá»‘t) - RECOMMENDED
   docker exec ollama ollama pull mistral

   # Neural Chat (7B, ~5GB, tá»‘i Æ°u cho chat)
   docker exec ollama ollama pull neural-chat

   # Phi (3.8B, ~2.5GB, nháº¹, nhanh)
   docker exec ollama ollama pull phi
   ```

4. **Test Ollama**:
   ```bash
   curl http://localhost:11434/api/tags
   ```
   Output sáº½ lÃ  danh sÃ¡ch models Ä‘Ã£ download.

---

### Option B: Direct Installation (Náº¿u khÃ´ng cÃ³ Docker)

1. **Download Ollama**:
   - https://ollama.ai/download
   - CÃ i Ä‘áº·t cho Windows/Mac/Linux

2. **Run Ollama**:

   ```bash
   ollama serve
   ```

   Máº·c Ä‘á»‹nh sáº½ listen á»Ÿ `http://localhost:11434`

3. **Download Model** (trong terminal khÃ¡c):
   ```bash
   ollama pull mistral
   ```

---

## ğŸ”„ Step 2: Verify Backend Setup

1. **Backend Ä‘Ã£ cáº¥u hÃ¬nh**:
   - âœ… `.env` cÃ³ `GEMINI_API_KEY`, `OLLAMA_URL`
   - âœ… Dependencies cÃ i Ä‘áº·t
   - âœ… Services táº¡o: AI, Chat modules
   - âœ… Endpoints: `POST /chat`, `POST /chat/index`

2. **Start Backend**:

   ```bash
   cd ekg-backend
   npm run start:dev
   ```

   Check logs:

   ```
   ğŸš€ API ready at http://localhost:3002/docs
   ```

---

## ğŸ“¦ Step 3: Index Entities to ChromaDB

ChromaDB lÆ°u vector embeddings cá»§a employees, skills, departments, projects Ä‘á»ƒ semantic search nhanh hÆ¡n.

1. **Call index endpoint**:

   ```bash
   curl -X POST http://localhost:3002/chat/index
   ```

   Response:

   ```json
   {
     "message": "Entities indexed successfully to ChromaDB"
   }
   ```

2. **Check ChromaDB files**:
   ```bash
   ls -la ekg-backend/data/chromadb/
   # Sáº½ tháº¥y: employees.json, skills.json, departments.json, projects.json
   ```

---

## ğŸ’¬ Step 4: Test Chat System

### Test via API (Postman/Curl):

```bash
curl -X POST http://localhost:3002/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Danh sÃ¡ch nhÃ¢n viÃªn"
  }'
```

Response:

```json
{
  "message": "Danh sÃ¡ch nhÃ¢n viÃªn",
  "response": "Danh sÃ¡ch nhÃ¢n viÃªn (42):\nâ€¢ Nguyá»…n VÄƒn A - Senior Dev\nâ€¢ Tráº§n Thá»‹ B - PM\n...",
  "queryType": "list-employees",
  "queryLevel": "simple",
  "processingTime": 145,
  "timestamp": "2024-11-20T..."
}
```

### Test via Frontend:

1. **Start Frontend**:

   ```bash
   cd ekg-frontend
   npm run dev
   ```

2. **Open Chat**:
   - VÃ o `http://localhost:3000`
   - Gá»­i tin nháº¯n: "Danh sÃ¡ch nhÃ¢n viÃªn"
   - Bot sáº½ respond tá»« `/chat` API

---

## ğŸ§ª Test Cases

### Simple Queries (instant)

- "Danh sÃ¡ch nhÃ¢n viÃªn" â†’ list-employees
- "TÃ¬m Nguyá»…n" â†’ search-global
- "CÃ³ bao nhiÃªu nhÃ¢n viÃªn" â†’ aggregate (medium)

### Medium Queries (ChromaDB)

- "TÃ¬m nhÃ¢n viÃªn cÃ³ ká»¹ nÄƒng Java" â†’ filter-search
- "So sÃ¡nh 2 dá»± Ã¡n" â†’ compare

### Complex Queries (Gemini)

- "TÆ° váº¥n cho tÃ´i má»™t nhÃ¢n viÃªn phÃ¹ há»£p" â†’ recommend
- "PhÃ¢n tÃ­ch nÄƒng lá»±c cá»§a team" â†’ analyze
- "Táº¡i sao cáº§n tuyá»ƒn thÃªm nhÃ¢n viÃªn?" â†’ reasoning

---

## ğŸ”§ Troubleshooting

### 1. **Ollama not responding**

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# If error, restart:
# Docker:
docker restart ollama

# Direct:
ollama serve
```

### 2. **Model not found**

```bash
# Check available models
curl http://localhost:11434/api/tags

# Pull missing model
docker exec ollama ollama pull mistral
# or
ollama pull mistral
```

### 3. **Gemini API Error**

- Check `.env` cÃ³ `GEMINI_API_KEY` khÃ´ng
- Key cÃ³ bá»‹ háº¿t quota khÃ´ng (check Google Cloud Console)

### 4. **ChromaDB not persisting**

- Check `CHROMADB_PATH=./data/chromadb` trong `.env`
- Folder `ekg-backend/data/chromadb` pháº£i tá»“n táº¡i
- Náº¿u khÃ´ng, backend sáº½ táº¡o tá»± Ä‘á»™ng

### 5. **Backend starts slowly**

- Láº§n Ä‘áº§u tiÃªn load Ollama model â†’ cháº­m (normal)
- Cached láº§n sau sáº½ nhanh

---

## ğŸ“Š Architecture

```
User Input (Chat.tsx)
    â†“
POST /chat endpoint
    â†“
QueryClassifier (phÃ¢n loáº¡i Ä‘á»™ khÃ³)
    â†“
    â”œâ”€ Simple â†’ handleSimpleQuery (Neo4j)
    â”œâ”€ Medium â†’ handleMediumQuery (ChromaDB + Neo4j)
    â””â”€ Complex â†’ handleComplexQuery (Gemini API)
    â†“
Response
```

---

## ğŸš€ Next Steps

1. âœ… CÃ i Ollama
2. âœ… Run backend
3. âœ… Index entities: `POST /chat/index`
4. âœ… Test chat
5. (Optional) Fine-tune query classifier trong `query-classifier.service.ts`
6. (Optional) Add more entity types tá»›i ChromaDB

---

## ğŸ“ API Endpoints

| Method | Endpoint       | Description                |
| ------ | -------------- | -------------------------- |
| POST   | `/chat`        | Process user query         |
| POST   | `/chat/index`  | Index entities to ChromaDB |
| GET    | `/chat/health` | Check system health        |

---

## ğŸ’¡ Tips

- **Vector search slow?** â†’ Increase batch size trong `ChromaDBService.addDocuments()`
- **Response quality poor?** â†’ Verify Ollama model loaded: `curl http://localhost:11434/api/tags`
- **Want better quality?** â†’ Use Gemini API cho complex queries (máº·c Ä‘á»‹nh Ä‘Ã£ setup)

---

**Happy chatting! ğŸ‰**
