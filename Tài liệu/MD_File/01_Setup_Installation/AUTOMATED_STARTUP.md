# ğŸš€ AI Chat System - Automated Startup Guide

## âœ¨ What's New

Backend giá» **tá»± Ä‘á»™ng kiá»ƒm tra, khá»Ÿi Ä‘á»™ng, vÃ  cáº¥u hÃ¬nh Ollama**! KhÃ´ng cáº§n setup thá»§ cÃ´ng ná»¯a!

---

## ğŸ¯ Quick Start (Simplest Way)

### Windows (PowerShell)

```powershell
.\start-dev.ps1
```

### Windows (CMD)

```cmd
start-dev.bat
```

### Linux/Mac

```bash
chmod +x start-dev.sh
./start-dev.sh
```

**That's it!** Script sáº½ tá»± Ä‘á»™ng:

1. âœ… Check Docker installed
2. âœ… Start/create Ollama container
3. âœ… Download model (náº¿u chÆ°a cÃ³)
4. âœ… Start backend

---

## ğŸ“‹ Auto-Init Flow

Khi backend start:

```
Backend Starting
    â†“
OllamaInitService.onModuleInit()
    â†“
Check Ollama running?
    â”œâ”€ NO â†’ Try auto-start via Docker
    â”‚   â”œâ”€ Container exists? â†’ docker start
    â”‚   â””â”€ Not exists? â†’ docker run (create new)
    â”œâ”€ Wait for Ollama ready
    â†“
Check model exists?
    â”œâ”€ NO â†’ docker exec ollama ollama pull mistral
    â†“
âœ… Ready for chat!
```

---

## ğŸ” Console Output Examples

### Successful Startup

```
============================================================
ğŸš€ Initializing Ollama...
============================================================
âœ… Ollama is running!
âœ… Model 'mistral' is ready!
============================================================
âœ… Ollama is fully configured and ready!
============================================================

[Nest] 20 Nov, 16:45:23     LOG [NestFactory] Starting Nest application...
[Nest] 20 Nov, 16:45:24     LOG [InstanceLoader] Neo4jModule dependencies initialized
[Nest] 20 Nov, 16:45:24     LOG [InstanceLoader] AiModule dependencies initialized
[Nest] 20 Nov, 16:45:25     LOG [InstanceLoader] ChatModule dependencies initialized
[Nest] 20 Nov, 16:45:25     LOG [NestFactory] Nest application successfully started
ğŸš€ API ready at http://localhost:3002/docs
```

### First Time (Auto-Pull Model)

```
============================================================
ğŸš€ Initializing Ollama...
============================================================
âœ… Ollama is running!
âš ï¸  Model 'mistral' not found
Pulling model 'mistral'...
Waiting for model... (1/60)
Waiting for model... (2/60)
...
âœ… Model 'mistral' pulled successfully!
============================================================
âœ… Ollama is fully configured and ready!
============================================================
```

### No Docker (Manual Setup Needed)

```
============================================================
ğŸš€ Initializing Ollama...
============================================================
âš ï¸  Ollama is not running!
Attempting to auto-start Ollama...
âŒ Failed to auto-start Ollama
âš ï¸  MANUAL SETUP REQUIRED:
1. Install Docker: https://www.docker.com/products/docker-desktop
2. Run: docker run -d --name ollama -p 11434:11434 -v ollama:/root/.ollama ollama/ollama
3. Download model: docker exec ollama ollama pull mistral
4. Restart backend: npm run start:dev
```

---

## ğŸ› ï¸ Manual Steps (If Auto-Init Fails)

### 1. Install Docker

- Windows/Mac: https://www.docker.com/products/docker-desktop
- Linux: https://docs.docker.com/get-docker/

### 2. Start Ollama Manually

```bash
# Create & start container
docker run -d \
  --name ollama \
  -p 11434:11434 \
  -v ollama:/root/.ollama \
  ollama/ollama

# Download model
docker exec ollama ollama pull mistral
```

### 3. Start Backend

```bash
cd ekg-backend
npm run start:dev
```

---

## ğŸ“‚ Startup Scripts

| File            | OS                   | Usage             |
| --------------- | -------------------- | ----------------- |
| `start-dev.ps1` | Windows (PowerShell) | `.\start-dev.ps1` |
| `start-dev.bat` | Windows (CMD)        | `start-dev.bat`   |
| `start-dev.sh`  | Linux/Mac            | `./start-dev.sh`  |

**Choose the one for your OS and run it!**

---

## ğŸ”§ Advanced: Manual Backend Start

If you prefer to start Ollama separately:

```bash
# Terminal 1: Start Ollama
docker run -d --name ollama -p 11434:11434 -v ollama:/root/.ollama ollama/ollama
docker exec ollama ollama pull mistral

# Terminal 2: Start Backend
cd ekg-backend
npm run start:dev

# Terminal 3: Start Frontend
cd ekg-frontend/apps/web
npm run dev
```

---

## âš™ï¸ How Auto-Init Works

### OllamaInitService

New file: `src/ai/ollama-init.service.ts`

**Features:**

- âœ… Checks if Ollama is running
- âœ… Auto-starts via Docker if not running
- âœ… Handles existing containers (restart instead of recreate)
- âœ… Auto-pulls model if missing
- âœ… Waits for Ollama to be ready
- âœ… Clear console messages for each step
- âœ… Graceful error handling

---

## ğŸ¯ Startup Scripts Features

### start-dev.ps1 (PowerShell)

```powershell
âœ… Colored output (Cyan, Green, Red, Yellow)
âœ… Check Docker installed
âœ… Create/start Ollama
âœ… Auto-navigate to ekg-backend
âœ… Start backend with npm run start:dev
```

### start-dev.bat (CMD)

```batch
âœ… Simple Windows batch script
âœ… Check Docker available
âœ… Create/start Ollama
âœ… Start backend
```

### start-dev.sh (Bash)

```bash
âœ… Cross-platform (Linux/Mac)
âœ… Check Docker installed
âœ… Create/start Ollama
âœ… Start backend
```

---

## ğŸ†˜ Troubleshooting

### "Docker is not installed"

â†’ Install Docker Desktop: https://www.docker.com/products/docker-desktop

### "Cannot find module... OllamaInitService"

â†’ Make sure you updated `ai.module.ts` with the import

### "Ollama timeout"

â†’ Docker might be starting slow, wait 10-15 seconds before retrying

### "Port 11434 already in use"

â†’ Another Ollama is running: `docker ps` to check, then `docker stop <container-id>`

---

## ğŸ“Š Comparison

| Method             | Setup Time   | Automation     | Flexibility |
| ------------------ | ------------ | -------------- | ----------- |
| **start-dev.ps1**  | 5 seconds    | Maximum âœ…âœ…âœ… | Good        |
| **Manual (old)**   | 5-10 minutes | None           | Full        |
| **Docker Compose** | 10 seconds   | High âœ…âœ…      | Good        |

---

## ğŸ‰ Summary

**Before**: Manual 5-10 minute setup  
**Now**: One command, ~5 seconds total!

```
# Just run ONE of these:
.\start-dev.ps1        # Windows PowerShell
start-dev.bat          # Windows CMD
./start-dev.sh         # Linux/Mac

# Done! Backend auto-configures Ollama and starts! ğŸš€
```

---

## ğŸ“š Next Steps

1. âœ… Run `start-dev.ps1` (or appropriate script)
2. âœ… Backend starts automatically with Ollama
3. âœ… In another terminal: `cd ekg-frontend/apps/web && npm run dev`
4. âœ… Open http://localhost:3000 and start chatting!

---

**No more manual setup! Everything is automated! ğŸ‰**
